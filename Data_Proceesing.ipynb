{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090de3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been cleaned and saved to 'cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Remove rows with missing data\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "cleaned_df.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Print a success message\n",
    "print(\"The data has been cleaned and saved to 'cleaned_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fffe500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We filter data for Twitter and Facebook and Save the combined data to 'Twitter_Facebook_data.csv'. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Filter data for Twitter and Facebook\n",
    "combined_data = df[df['Platform'].isin(['Twitter', 'Facebook'])]\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_data.to_csv('Twitter_Facebook_data.csv', index=False)\n",
    "\n",
    "print(\"We filter data for Twitter and Facebook and Save the combined data to 'Twitter_Facebook_data.csv'. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbb661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16595\n",
      "[[3091.]\n",
      " [ 356.]\n",
      " [2424.]\n",
      " ...\n",
      " [8357.]\n",
      " [ 300.]\n",
      " [1166.]] <class 'numpy.ndarray'>\n",
      "[[ 356.]\n",
      " [8261.]\n",
      " [3734.]\n",
      " ...\n",
      " [ 289.]\n",
      " [1809.]\n",
      " [3602.]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Twitter_Facebook_data.csv')\n",
    "\n",
    "data = data[data['Agency'].isin(['311', 'ACS', 'CAU', 'Change by Us', 'City Charter', 'City Store', 'Culture', 'DCA', 'DEP',\\\n",
    "                                'DFTA (aging)', 'DFTA', 'DHS', 'DHS (Homeless Service)', 'DOB', 'DOB: Cool Roofs',\\\n",
    "                                'DOB: UrbanCanvas', 'DOE', 'NYC Schools', 'NYC TeachingFellows', 'I teach NYC', 'NYC Health',\\\n",
    "                                'Eating Healthy NYC', 'NYCKnows', 'NYCQuites', 'DOI','NYC IT & Telecomm',\\\n",
    "                                 'DOT (Department of Transportaion)', 'JanetteSadikKhan (Not Available)',\\\n",
    "                                'DOT (Department of Transportaion)', 'You the Man NYC (not available)', 'NYC Parks',\\\n",
    "                                'Pearl_Squirrel (not available)', 'DYCD', 'NYC zerowaste',  'Applied Sciences NYC',\\\n",
    "                                'EDC (New York City Economic Development Corporation)', 'energyNYC', 'FDNY (Fire Department)',\\\n",
    "                                'FUND', 'HHC', 'HDP', 'HIA', 'HRA (Human Resource Administration)', 'NYC Dad', 'NYC LatinMedia',\\\n",
    "                                'LPC', 'Materials for the Arts', 'MOIA', \"NYC Mayor's Office of Immigrant Affairs\",\\\n",
    "                                'MOME', 'MOPD', 'NYCgo', 'nycshop', 'NYCgo.au', 'NYCgo.br', 'NYCgo.ca','NYCgo.de',\\\n",
    "                                'NYCgo.es', 'NYCgo.fr', 'NYCgo.it', 'NYCgo.uk', 'NYC Digital', 'NYC Gov','NYC Mayors Cup',\\\n",
    "                                'NYC Waterfront', 'NYCCFB', 'NYC Votes', 'NYCGLOBAL', 'NYCHA', 'NYCService',\\\n",
    "                                'OCDV','YouCanTooNYC', 'NYC Recycles2', \\\n",
    "                                'SBS (Small Business Service)', 'SBS', 'SBS - Workforce1', 'SBS - Workforce1', 'VAC',\\\n",
    "                                'Vets'])]\n",
    "\n",
    "\n",
    "\n",
    "# Filter for Instagram and Twitter data\n",
    "facebook_data = data[data['Platform'] == 'Facebook']\n",
    "twitter_data = data[data['Platform'] == 'Twitter']\n",
    "\n",
    "# Merge Instagram and Twitter data based on the date\n",
    "merged_data = pd.merge(facebook_data, twitter_data, on='Agency', suffixes=('_facebook', '_twitter'))\n",
    "\n",
    "# Select the number of downloads for Facebook as X (independent variable)\n",
    "X = merged_data['Likes/Followers/Visits/Downloads_facebook'].values.reshape(-1, 1)\n",
    "print(len(X))\n",
    "\n",
    "# Select the number of downloads for Twitter as y (dependent variable)\n",
    "y = merged_data['Likes/Followers/Visits/Downloads_twitter'].values.reshape(-1, 1)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train1, type(X_train1))\n",
    "print(X_test1, type(X_test1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81daa1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
